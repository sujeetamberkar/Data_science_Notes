{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d473cc7b-b29f-4b3e-bff3-718a01291c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nWeb scraping is the process of extracting information directly from websites. \\nIt's used to gather data from various sources for different purposes such as analysis, research, or business insights. \\nThree areas where it's commonly used are:\\n\\n    1) Market Research: It helps in gathering information about competitors, market trends, and customer feedback.\\n    2) Sentiment Analysis: It aids in collecting data from social media and forums to understand public sentiment about a topic.\\n    3) Job Listings: It's used to aggregate job postings from multiple sites for centralized viewing.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\"\"\"\n",
    "Web scraping is the process of extracting information directly from websites. \n",
    "It's used to gather data from various sources for different purposes such as analysis, research, or business insights. \n",
    "Three areas where it's commonly used are:\n",
    "\n",
    "    1) Market Research: It helps in gathering information about competitors, market trends, and customer feedback.\n",
    "    2) Sentiment Analysis: It aids in collecting data from social media and forums to understand public sentiment about a topic.\n",
    "    3) Job Listings: It's used to aggregate job postings from multiple sites for centralized viewing.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abce1b3e-f247-4041-8d91-6bf257138b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n    1) Manual Copy-Paste: This is a basic method where data is manually copied and pasted into a local file.\\n    2) HTML Parsing: This involves analyzing a web page's HTML code to extract the data you need.\\n    3) DOM Parsing: This method deals with the Document Object Model (DOM) of the web page.\\n    4) API Interface: Some websites provide APIs which can be used to directly access the data.\\n    5) Web Scraping Tools: There are various software or libraries like BeautifulSoup, Scrapy, and Selenium designed \\n                           specifically for web scraping.\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2. What are the different methods used for Web Scraping?\n",
    "\"\"\"\n",
    "    1) Manual Copy-Paste: This is a basic method where data is manually copied and pasted into a local file.\n",
    "    2) HTML Parsing: This involves analyzing a web page's HTML code to extract the data you need.\n",
    "    3) DOM Parsing: This method deals with the Document Object Model (DOM) of the web page.\n",
    "    4) API Interface: Some websites provide APIs which can be used to directly access the data.\n",
    "    5) Web Scraping Tools: There are various software or libraries like BeautifulSoup, Scrapy, and Selenium designed \n",
    "                           specifically for web scraping.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b25ceb-1e1e-4b57-800c-c379fcc57bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBeautiful Soup is a Python library used for web scraping purposes to pull the data out of HTML and XML files. \\nIt is often used because it provides simple, Pythonic idioms for iterating, searching, and modifying parsed trees, making it \\neasy to navigate, search, and modify parse trees.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Q3. What is Beautiful Soup? Why is it used?\n",
    "\n",
    "\"\"\"\n",
    "Beautiful Soup is a Python library used for web scraping purposes to pull the data out of HTML and XML files. \n",
    "It is often used because it provides simple, Pythonic idioms for iterating, searching, and modifying parsed trees, making it \n",
    "easy to navigate, search, and modify parse trees.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fba643-d804-438b-9dcc-5064edf784e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlask is used in this Web Scraping project because it is a lightweight and flexible web framework in Python, \\nmaking it suitable for building simple GUI web applications.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?\n",
    "\n",
    "\"\"\"\n",
    "Flask is used in this Web Scraping project because it is a lightweight and flexible web framework in Python, \n",
    "making it suitable for building simple GUI web applications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f09936cd-df1a-450e-8880-b16f4c30c7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIn this project, the AWS services used are Elastic Beanstalk and AWS CodePipeline.\\n\\nElastic Beanstalk simplifies application deployment and management by handling infrastructure provisioning, scalability, \\nmonitoring, and lifecycle management. It abstracts away underlying complexity, making it easier to deploy and manage web \\napplications on AWS.\\n\\n\\nAWS CodePipeline is used to automate the software release process by enabling continuous integration and deployment (CI/CD). \\nIt provides a visual workflow, scalability, and integrates with other AWS services, facilitating faster and reliable application \\ndeployments.AWS CodePipeline is used to automate the software release process by enabling continuous integration and deployment \\n(CI/CD). It provides a visual workflow, scalability, and integrates with other AWS services, facilitating faster and reliable \\napplication deployments.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\"\"\"\n",
    "In this project, the AWS services used are Elastic Beanstalk and AWS CodePipeline.\n",
    "\n",
    "Elastic Beanstalk simplifies application deployment and management by handling infrastructure provisioning, scalability, \n",
    "monitoring, and lifecycle management. It abstracts away underlying complexity, making it easier to deploy and manage web \n",
    "applications on AWS.\n",
    "\n",
    "\n",
    "AWS CodePipeline is used to automate the software release process by enabling continuous integration and deployment (CI/CD). \n",
    "It provides a visual workflow, scalability, and integrates with other AWS services, facilitating faster and reliable application \n",
    "deployments.AWS CodePipeline is used to automate the software release process by enabling continuous integration and deployment \n",
    "(CI/CD). It provides a visual workflow, scalability, and integrates with other AWS services, facilitating faster and reliable \n",
    "application deployments.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093c5a5-955a-4792-bd92-dec9bb0754f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
